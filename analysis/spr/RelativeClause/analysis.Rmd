---
title: 'SAP Benchmark (SPR): RC subset'
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(lme4)
library(tidyverse)
library(ggplot2)
library(brms)
library(bayestestR)

source('../../shared/util.R')
```

## Load in data


### Empirical data

```{r}

rt.data <- read.csv("../../../preprocessed_data/RelativeClauseSet.csv", header=TRUE) %>%
  filter(RT <= 7000) %>%
  filter(RT > 0) %>%
  rename(participant = MD5)

filler.data <- read.csv("../../../preprocessed_data/Fillers.csv", header = TRUE) %>%
  filter(RT <=7000) %>%
  filter(RT > 0) %>%
  rename(participant = MD5)

```

**Correcting for the effect of word position**
```{r}

# position_fit_lmer <- lmer(RT ~ scale(WordPosition) + (1 + scale(WordPosition) | participant), filler.data)
position_fit_lmer_nocor <- lmer(RT ~ scale(WordPosition) + (1 + scale(WordPosition) || participant), filler.data)

position_fit_lm <- lm(RT ~ scale(WordPosition), filler.data)

#summary(position_fit_lmer)
summary(position_fit_lmer_nocor)
summary(position_fit_lm)

rt.data$wordpos_predrt <- predict(position_fit_lmer_nocor, rt.data)
rt.data$wordpos_predrt_lm <- predict(position_fit_lm, rt.data)

rt.data$corrected_rt <- rt.data$RT - rt.data$wordpos_predrt
rt.data$corrected_rt_lm <- rt.data$RT - rt.data$wordpos_predrt_lm

```


### Predicted data from language models

```{r, cache=TRUE}

predicted_dat_rc <- Predicting_RT_with_spillover(rt.data, 'RelativeClause')
predicted_dat_filler <-  Predicting_RT_with_spillover(filler.data, 'filler')

print(getwd())

temp <- list()

i <- 1
for(m in unique(predicted_dat_rc$model)){
  print(m)
  curr_rc <- subset(predicted_dat_rc, model == m)
  curr_filler <- subset(predicted_dat_filler, model == m)
  print(paste(nrow(curr_filler), nrow(predicted_dat_filler)))
  
  curr_fit <-  lmer(predicted ~ scale(WordPosition) + (1 + scale(WordPosition) || participant),
                    curr_filler)

  print(summary(curr_fit))

  curr_rc$wordpos_predicted = predict(curr_fit, curr_rc)
  curr_rc$corrected_predicted = curr_rc$predicted - curr_rc$wordpos_predicted

  temp[[i]] <- curr_rc
  i <- i + 1
}

predicted_dat <- dplyr::bind_rows(temp)

predicted_dat <- predicted_dat %>%
  mutate(Type = factor(Type, levels = c('RC_Subj', 'RC_Obj')),
         Type_num = ifelse(Type == 'RC_Subj', 0, 1))

rm(temp)

```

## Analyses with LMER models

### Empirical data

```{r, cache=TRUE}

verb_dat <- rt.data %>%
  filter(ROI == 0) %>%
  mutate(Type = factor(Type, levels = c('RC_Subj', 'RC_Obj')),
         Type_num = ifelse(Type == 'RC_Subj', 0, 1))

contrasts(verb_dat$Type)

## part intercept is 0 because we removed out this intercept through word pos correction
fit_verb_lmer <- lmer(corrected_rt ~ Type_num + (0 + Type_num || participant) + (1 + Type_num || item), data=verb_dat)

summary(fit_verb_lmer)

saveRDS(fit_verb_lmer, './saved_objects/fit_verb_lmer')


```

**Looking at other word positions**
```{r, cache=TRUE}
det_dat <- rt.data %>%
  filter(ROI == 1) %>%
  mutate(Type = factor(Type, levels = c('RC_Subj', 'RC_Obj')),
         Type_num = ifelse(Type == 'RC_Subj', 0, 1))

contrasts(det_dat$Type)

## part intercept is 0 because we removed out this intercept through word pos correction
fit_det_lmer <- lmer(corrected_rt ~ Type_num + (0 + Type_num | participant) + (1 + Type_num | item), data=det_dat)

summary(fit_det_lmer)

saveRDS(fit_det_lmer, './saved_objects/fit_det_lmer')



noun_dat <- rt.data %>%
  filter(ROI == 2) %>%
  mutate(Type = factor(Type, levels = c('RC_Subj', 'RC_Obj')),
         Type_num = ifelse(Type == 'RC_Subj', 0, 1))

contrasts(noun_dat$Type)

## part intercept is 0 because we removed out this intercept through word pos correction
fit_noun_lmer <- lmer(corrected_rt ~ Type_num + (0 + Type_num | participant) + (1 + Type_num | item), data=noun_dat)

summary(fit_noun_lmer)

saveRDS(fit_noun_lmer, './saved_objects/fit_noun_lmer')

```

### Predicted data

```{r, cache=TRUE}

fit_verb_lmer_pred_lstm <- lmer(corrected_predicted ~ Type_num +
                              (0 + Type_num || participant) +
                              (1 + Type_num || item),
                  data=subset(predicted_dat, ROI==0 & model == 'lstm')
                  )

saveRDS(fit_verb_lmer_pred_lstm, './saved_objects/fit_verb_lmer_pred_lstm')

summary(fit_verb_lmer_pred_lstm)

                                        

fit_verb_lmer_pred_gpt2 <- lmer(corrected_predicted ~ Type_num +
                              (0 + Type_num || participant) +
                              (1 + Type_num || item),
                  data=subset(predicted_dat, ROI==0 & model == 'gpt2')
                  )

saveRDS(fit_verb_lmer_pred_gpt2, './saved_objects/fit_verb_lmer_pred_gpt2')

summary(fit_verb_lmer_pred_gpt2)


#fit_det_bayes_pred <- readRDS('./saved_objects/fit_det_bayes_ored_prior1')

```


```{r}

create_dfs_lmer <- function(fit, model_name){
  coef_typenum <- coef(summary(fit))[2, 'Estimate']
  se_typenum <- coef(summary(fit))[2, 'Std. Error']
  
  by_construction <- data.frame(ROI = 0,
                                coef = 'RC',
                                mean = coef_typenum,
                                lower = coef_typenum-(2*se_typenum),
                                upper = coef_typenum+(2*se_typenum))
  dir <- '../../../plots/spr/RelativeClause/'
  constr_fname <- ifelse(model_name == 'human', 
                         paste0(dir, 'by_construction_lmer.rds'),
                         paste0(dir, 'by_construction_lmer_', model_name, '.rds'))
  
  saveRDS(by_construction, constr_fname)
  
  
  by_item <- data.frame(ranef(fit)[['item']]) %>%
    add_rownames(var='item') %>%
    mutate(mean = coef_typenum + Type_num,
           lower = NA,
           upper = NA,
           ROI = 0,
           coef = 'RC') %>%
    select(item, ROI, coef, mean, lower, upper)
  
  item_fname <- ifelse(model_name == 'human', 
                         paste0(dir, 'by_item_lmer.rds'),
                         paste0(dir, 'by_item_lmer_', model_name, '.rds'))
  
  saveRDS(by_item, item_fname)
  
}
```


```{r}

create_dfs_lmer(fit_verb_lmer, 'human')
create_dfs_lmer(fit_verb_lmer_pred_gpt2, 'gpt2')
create_dfs_lmer(fit_verb_lmer_pred_lstm, 'lstm')

```


## Analyses with BRMS model

### Empirical data

```{r}
prior1 <- c(prior("normal(300,1000)", class = "Intercept"),
            prior("normal(0,150)", class = "b"),  
            prior("normal(0,200)", class = "sd"),    
            prior("normal(0,500)", class = "sigma"))

#Note brms automatically truncates the distributions for sd and sigma.

```


```{r, cache=TRUE}

fit_verb_bayes <- brm(corrected_rt ~ Type_num + (0 + Type_num || participant) + (1 + Type_num || item),
                  data=verb_dat,
                  prior = prior1,
                  cores = 4,
                  iter = 6000,
                  seed = 117
                  )

saveRDS(fit_verb_bayes, './saved_objects/fit_verb_bayes_prior1')

summary(fit_verb_bayes)


#fit_verb_bayes <- readRDS('./saved_objects/fit_verb_bayes_prior1')

```

```{r, cache=TRUE}

fit_det_bayes <- brm(corrected_rt ~ Type_num + (0 + Type_num || participant) + (1 + Type_num || item),
                  data=det_dat,
                  prior = prior1,
                  cores = 4,
                  iter = 6000,
                  seed = 117
                  )

saveRDS(fit_det_bayes, './saved_objects/fit_det_bayes_prior1')

summary(fit_det_bayes)


#fit_det_bayes <- readRDS('./saved_objects/fit_det_bayes_prior1')

```



```{r, cache=TRUE}

fit_noun_bayes <- brm(corrected_rt ~ Type_num + (0 + Type_num || participant) + (1 + Type_num || item),
                  data=noun_dat,
                  prior = prior1,
                  cores = 4,
                  iter = 6000,
                  seed = 117
                  )

saveRDS(fit_noun_bayes, './saved_objects/fit_noun_bayes_prior1')

summary(fit_noun_bayes)


#fit_noun_bayes <- readRDS('./saved_objects/fit_noun_bayes_prior1')

```


```{r, cache=TRUE}

emp_dat_verb <- reshape_item_dat(fit_verb_bayes, "item") %>%
  mutate(ROI = 0)
emp_dat_det <- reshape_item_dat(fit_det_bayes, "item") %>%
  mutate(ROI = 1)
emp_dat_noun <- reshape_item_dat(fit_noun_bayes, "item")%>%
  mutate(ROI = 2)

emp_dat <- dplyr::bind_rows(emp_dat_verb, emp_dat_det, emp_dat_noun)
 
rm(emp_dat_verb, emp_dat_det, emp_dat_noun)

saveRDS(emp_dat, './saved_objects/rc_subset_sampledsumm_empirical')


```


```{r}

by_construction <- emp_dat %>%
  mutate(diff = b_Type_num,
         coef = 'RC') %>%
  group_by(ROI, coef) %>%
  summarise(mean = mean(diff),
            lower = quantile(diff, 0.025)[[1]],
            upper = quantile(diff, 0.975)[[1]])

saveRDS(by_construction, '../../../plots/spr/RelativeClause/by_construction.rds')

by_item <- emp_dat %>%
  mutate(diff = b_Type_num + r_Type_num,
         coef = 'RC',
         item = as.numeric(item)) %>%
  group_by(item,ROI, coef) %>%
  summarise(mean = mean(diff),
            lower = quantile(diff, 0.025)[[1]],
            upper = quantile(diff, 0.975)[[1]]) 

saveRDS(by_item, '../../../plots/spr/RelativeClause/by_item.rds')

by_item_surprisalmerged <- merge_surprisal(rt.data,by_item,"RelativeClause")

```

```{r}
# Plot_empirical_construction_level(by_construction,"RelativeClause")
# 
# by_item$coef <- 'RC'
# Plot_itemwise_by_magnitude(by_item,"RelativeClause",ROI='Verb')
```


### Predicted data

```{r, cache=TRUE}

fit_verb_bayes_pred_gpt2 <- brm(corrected_predicted ~ Type_num +
                              (0 + Type_num || participant) +
                              (1 + Type_num || item),
                  data=subset(predicted_dat, ROI==0 & model == 'gpt2'),
                  prior = prior1,
                  cores = 4,
                  iter = 12000,
                  seed = 117
                  )

saveRDS(fit_verb_bayes_pred_gpt2, './saved_objects/fit_verb_bayes_pred_gpt2_prior1')


#fit_verb_bayes_pred_gpt2 <- readRDS('./saved_objects/fit_verb_bayes_pred_gpt2_prior1')

summary(fit_verb_bayes_pred_gpt2)

```


```{r, cache=TRUE}

fit_verb_bayes_pred_lstm <- brm(corrected_predicted ~ Type_num +
                              (0 + Type_num || participant) +
                              (1 + Type_num || item),
                  data=subset(predicted_dat, ROI==0 & model == 'lstm'),
                  prior = prior1,
                  cores = 4,
                  iter = 12000,
                  seed = 117
                  )

saveRDS(fit_verb_bayes_pred_lstm, './saved_objects/fit_verb_bayes_pred_lstm_prior1')


fit_verb_bayes_pred_lstm <- readRDS('./saved_objects/fit_verb_bayes_pred_lstm_prior1')

summary(fit_verb_bayes_pred_lstm)

```


```{r, cache=TRUE}

pred_dat_verb_gpt2 <- reshape_item_dat(fit_verb_bayes_pred_gpt2, "item") %>%
   mutate(ROI = 0,
          model = 'gpt2')


pred_dat_verb_lstm <- reshape_item_dat(fit_verb_bayes_pred_lstm, "item") %>%
   mutate(ROI = 0,
          model = 'lstm')

pred_dat_verb <- dplyr::bind_rows(pred_dat_verb_gpt2, pred_dat_verb_lstm)


saveRDS(pred_dat_verb_lstm, './saved_objects/rc_subset_sampledsumm_lstm')
saveRDS(pred_dat_verb_gpt2, './saved_objects/rc_subset_sampledsumm_gpt2')

saveRDS(pred_dat_verb, './saved_objects/rc_subset_sampledsumm_predicted')


```


```{r}

for(m in unique(pred_dat_verb$model)){
  curr_dat <- subset(pred_dat_verb, model == m)
  print(paste(nrow(curr_dat), nrow(pred_dat_verb)))
  
  curr_by_construction <- curr_dat %>%
    mutate(diff = b_Type_num,
           coef='RC') %>%
    group_by(ROI, coef) %>%
    summarise(mean = mean(diff),
              lower = quantile(diff, 0.025)[[1]],
              upper = quantile(diff, 0.975)[[1]])
  
  dir <- '../../../plots/spr/RelativeClause/'
  
  saveRDS(curr_by_construction, paste0(dir,'by_construction_', m, '.rds'))
  
  curr_by_item <- curr_dat %>%
    mutate(diff = b_Type_num + r_Type_num,
           coef = 'RC',
           item = as.numeric(item)) %>%
    group_by(item,ROI, coef) %>%
    summarise(mean = mean(diff),
              lower = quantile(diff, 0.025)[[1]],
              upper = quantile(diff, 0.975)[[1]]) 
  
  saveRDS(curr_by_item, paste0(dir,'by_item_', m, '.rds'))
}


```

